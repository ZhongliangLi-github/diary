# Fastertransformer

## 一、介绍

​	NVIDIA Faster Transformer是一个库，用于实现基于Transformer的神经网络推理的加速引擎，特别强调大型模型。Faster Transformer包含Transformer块的高度优化版本实现，其中包含编码器和解码器部分。它是由C++/CUDA编写，依赖于高度优化的cuBLAS、cuBLASLt和cuSPARSELt库，可以在GPU上构建最快的Transformer推理流程。

​	与深度学习训练的通用框架相比，FasterTransformer能够获得更快的推理管道，并且基于Transformer的神经网络具有更低的延迟和更高的吞吐量。

![](../../figs.assets/image-20230216211152721.png)

Triton推理服务器，具有多个后端，用于对使用不同框架训练的模型进行推理

​	带有FasterTransformer后端的Triton支持wenet、T5、swin、GPT等模型推理。

![](../../figs.assets/b4f5ffc8770141538ca906ff29f19cbb.png)

## 二、WeNet 应用

### 2.1 编码器 ONNX

​	采用 `WenetEncoderPlugin` 集成了所有编码器模块

![](../../figs.assets/image-20230216212346060.png)

![](../../figs.assets/image-20230216212400383.png)

### 2.2 解码器 ONNX

​	采用 `WenetDecoderPlugin` 集成了所有编码器模块

![](../../figs.assets/image-20230216212550501.png)

![](../../figs.assets/image-20230216212607069.png)

## 3、性能分析

​	采用 Perf_analyzer 工具对性能进行分析，对于 ONNX 模型 和经 FasterTransformer 加速的 tensorrt 模型，比较了模型推理的吞吐率和平均时延：

| fastertransformer/ONNX   |                  |                   |                   |              |
| :----------------------- | :--------------: | :---------------: | :---------------: | :----------: |
| **batch size(并发度=2)** |      **2**       |       **4**       |       **8**       |    **16**    |
| 吞吐率(infer/s)          |   49.2 / 34.8    |    72.8 / 41.6    |    86.4 / 38.4    |   83.2 / -   |
| 平均时延(ms)             | 81.505 / 115.982 | 109.241 / 192.726 | 187.399 / 394.910 | 376.351 / -  |
| **batch size(并发度=8)** |      **2**       |       **4**       |       **8**       |    **16**    |
| 吞吐率(infer/s)          |   48.8 / 30.4    |    81.6 / 40.8    |     91.2 / -      |   86.4 / -   |
| 平均时延(ms)             | 81.297 / 526.399 | 402.041 / 830.06  |    734.136 / -    | 1422.577 / - |

> ‘-’：表示 OOM 无法完成推理





| 部署在台式机             |        |        |        |         |
| ------------------------ | ------ | ------ | ------ | ------- |
| **batch size(并发度=2)** | **2**  | **4**  | **8**  | **16**  |
| 吞吐率(infer/s)          | 488    | 641.6  | 771.2  | 851.2   |
| 平均时延(ms)             | 8.193  | 12.474 | 20.712 | 37.604  |
| **batch size(并发度=8)** | **2**  | **4**  | **8**  | **16**  |
| 吞吐率(infer/s)          | 698.8  | 919.2  | 1049.6 | 1179.2  |
| 平均时延(ms)             | 22.890 | 34.808 | 53.477 | 108.696 |

